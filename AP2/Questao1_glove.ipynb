{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2f9ae02c53474ae8b59680263a79cfa1543626f"},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nfrom nltk.stem import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import preprocessing\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense, Bidirectional\nimport matplotlib.pyplot as plt\nfrom keras.layers import LSTM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0b976f23078c358f200f752346ab68901ba6afc"},"cell_type":"code","source":"df = pd.read_csv('../input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3c5e1044eb29074461b8d66f9cf7b8027806af0"},"cell_type":"code","source":"df = df.dropna(how='any',axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c32b9c4aa872db233464ef269a6626e1b34a0e4"},"cell_type":"code","source":"df = df[['Review Text','Rating']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"X = df.iloc[:,0].values\ny = df.iloc[:,1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12e282c42a175168e7502e3df6f95a0da470232a"},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\ny = le.fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a563961a3db126cc160e4cba2f5d590fc2bc7d4"},"cell_type":"markdown","source":"# questao 1 g"},{"metadata":{"trusted":true,"_uuid":"3c115eb810202e68e98e33409c3986ce5c7d1152"},"cell_type":"code","source":"maxlen = 200 # Cuts off reviews after 200 words\nmax_words = 1000 # Considers only the top 1000 words in the dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"659e8f60f6894fd314fa2cba17951113c9e85e31"},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0515863ff42449c94cd519cd51997b8d8493d93d"},"cell_type":"code","source":"word_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23dbcd50c4bf1b197559fed85152683202ee594b"},"cell_type":"code","source":"data = pad_sequences(sequences, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07fec8798c8e5c7f724aaf4f5859b88dbfa66cbe"},"cell_type":"code","source":"print('Shape of data tensor:', data.shape)\nprint('Shape of label tensor:', y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb3d83314644fa756b00526e3d923d86c4670858"},"cell_type":"code","source":"X_total, X_test, y_total, y_test = train_test_split(data, y, \n                                                    test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9e4eabb3556f55ea8c69eedd51753e34bcbaeb4"},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_total, y_total, \n                                                    test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a108c4cdbb8511abf92638f7bf97d2cfad370184"},"cell_type":"code","source":"X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca24d7b7e6c0b443f5f92872d5116210f8502b94"},"cell_type":"code","source":"X_val.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16e88a6421b4d58a832c19ca1fef37fa465ca090"},"cell_type":"code","source":"glove_dir = '../input/glove-global-vectors-for-word-representation/'\nembeddings_index = {}\nf = open(os.path.join(glove_dir, 'glove.6B.50d.txt'))\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\nprint('Found %s word vectors.' % len(embeddings_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ba8c2867c7e376b363156bf46916f881fd5f8b1"},"cell_type":"code","source":"embedding_dim = 50\nembedding_matrix = np.zeros((max_words, embedding_dim))\nfor word, i in word_index.items():\n    if i < max_words:\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector #Words not found in the embedding index will be all zeros. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4137e1e166e6a0bf19fde3d682f8f953eeab59e"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(max_words, embedding_dim, input_length=maxlen))\nmodel.add(LSTM(32, dropout=0.3))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(5, activation='softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61f505efb7a941ff70060b9c1ae742858e22b08c"},"cell_type":"code","source":"model.compile(optimizer='rmsprop',\nloss='sparse_categorical_crossentropy',\nmetrics=['acc'])\n\nhistory = model.fit(X_train, y_train,\nepochs=20,\nbatch_size=128,\nvalidation_data=(X_val, y_val))\nmodel.save_weights('pre_trained_glove_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f01b91261bac803c9bc5232dbc9cd96e7c1ded68"},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed8d496a2d5aee60427052018e6959876a786f1f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}