{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['glove-global-vectors-for-word-representation', 'womens-ecommerce-clothing-reviews']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d2f9ae02c53474ae8b59680263a79cfa1543626f"
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nfrom nltk.stem import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import preprocessing\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense, Bidirectional\nimport matplotlib.pyplot as plt\nfrom keras.layers import LSTM",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a0b976f23078c358f200f752346ab68901ba6afc"
      },
      "cell_type": "code",
      "source": "df = pd.read_csv('../input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv')",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a3c5e1044eb29074461b8d66f9cf7b8027806af0"
      },
      "cell_type": "code",
      "source": "df = df.dropna(how='any',axis=0)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5c32b9c4aa872db233464ef269a6626e1b34a0e4"
      },
      "cell_type": "code",
      "source": "df = df[['Review Text','Rating']]\ndf.head()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "                                         Review Text  Rating\n2  I had such high hopes for this dress and reall...       3\n3  I love, love, love this jumpsuit. it's fun, fl...       5\n4  This shirt is very flattering to all due to th...       5\n5  I love tracy reese dresses, but this one is no...       2\n6  I aded this in my basket at hte last mintue to...       5",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Text</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>I had such high hopes for this dress and reall...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This shirt is very flattering to all due to th...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>I love tracy reese dresses, but this one is no...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>I aded this in my basket at hte last mintue to...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "X = df.iloc[:,0].values\ny = df.iloc[:,1].values",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f3488130d966eaeee8b2a603c3ac0c27788416cf"
      },
      "cell_type": "code",
      "source": "le = preprocessing.LabelEncoder()\ny = le.fit_transform(y)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8a563961a3db126cc160e4cba2f5d590fc2bc7d4"
      },
      "cell_type": "markdown",
      "source": "# questao 1 g"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c115eb810202e68e98e33409c3986ce5c7d1152"
      },
      "cell_type": "code",
      "source": "maxlen = 200 # Cuts off reviews after 200 words\nmax_words = 1000 # Considers only the top 1000 words in the dataset",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "659e8f60f6894fd314fa2cba17951113c9e85e31"
      },
      "cell_type": "code",
      "source": "tokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0515863ff42449c94cd519cd51997b8d8493d93d"
      },
      "cell_type": "code",
      "source": "word_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found 14244 unique tokens.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "23dbcd50c4bf1b197559fed85152683202ee594b"
      },
      "cell_type": "code",
      "source": "data = pad_sequences(sequences, maxlen=maxlen)",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07fec8798c8e5c7f724aaf4f5859b88dbfa66cbe"
      },
      "cell_type": "code",
      "source": "print('Shape of data tensor:', data.shape)\nprint('Shape of label tensor:', y.shape)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Shape of data tensor: (19662, 200)\nShape of label tensor: (19662,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cb3d83314644fa756b00526e3d923d86c4670858"
      },
      "cell_type": "code",
      "source": "X_total, X_test, y_total, y_test = train_test_split(data, y, \n                                                    test_size=0.1, random_state=42)",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b9e4eabb3556f55ea8c69eedd51753e34bcbaeb4"
      },
      "cell_type": "code",
      "source": "X_train, X_val, y_train, y_val = train_test_split(X_total, y_total, \n                                                    test_size=0.1, random_state=42)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a108c4cdbb8511abf92638f7bf97d2cfad370184"
      },
      "cell_type": "code",
      "source": "X_train.shape, X_test.shape",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "((15925, 200), (1967, 200))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ca24d7b7e6c0b443f5f92872d5116210f8502b94"
      },
      "cell_type": "code",
      "source": "X_val.shape, y_val.shape",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "((1770, 200), (1770,))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "16e88a6421b4d58a832c19ca1fef37fa465ca090"
      },
      "cell_type": "code",
      "source": "glove_dir = '../input/glove-global-vectors-for-word-representation/'\nembeddings_index = {}\nf = open(os.path.join(glove_dir, 'glove.6B.50d.txt'))\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\nprint('Found %s word vectors.' % len(embeddings_index))",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found 400000 word vectors.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ba8c2867c7e376b363156bf46916f881fd5f8b1"
      },
      "cell_type": "code",
      "source": "embedding_dim = 50\nembedding_matrix = np.zeros((max_words, embedding_dim))\nfor word, i in word_index.items():\n    if i < max_words:\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector #Words not found in the embedding index will be all zeros. ",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e4137e1e166e6a0bf19fde3d682f8f953eeab59e"
      },
      "cell_type": "code",
      "source": "model = Sequential()\nmodel.add(Embedding(max_words, embedding_dim, input_length=maxlen))\nmodel.add(LSTM(32, dropout=0.3))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(5, activation='softmax'))\nmodel.summary()",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 200, 50)           50000     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 32)                10624     \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                1056      \n_________________________________________________________________\ndense_2 (Dense)              (None, 5)                 165       \n=================================================================\nTotal params: 61,845\nTrainable params: 61,845\nNon-trainable params: 0\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "61f505efb7a941ff70060b9c1ae742858e22b08c"
      },
      "cell_type": "code",
      "source": "model.compile(optimizer='rmsprop',\nloss='sparse_categorical_crossentropy',\nmetrics=['acc'])\n\nhistory = model.fit(X_train, y_train,\nepochs=20,\nbatch_size=128,\nvalidation_data=(X_val, y_val))\nmodel.save_weights('pre_trained_glove_model.h5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f01b91261bac803c9bc5232dbc9cd96e7c1ded68"
      },
      "cell_type": "code",
      "source": "acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7e13914f66d2d44ac2b299cb1b71b9944e658eb4"
      },
      "cell_type": "code",
      "source": "loss, acc = model.evaluate(X_test, y_test)\nloss, acc",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f7f5c345a1bbd01e15f3d42d6e7735f152e022a8"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}