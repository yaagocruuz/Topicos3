{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "(1,5 pontos) O número de imagens da Maggie Simpson são apenas 128,\n",
    "comparada a Homer Simpson, ela é pelo menos 10 vezes menor. Adicione as\n",
    "imagens de Maggie ao seu conjunto de dados. Qual técnica você poderia utilizar\n",
    "para que a classe Maggie Simpson não ficasse em desvantagem em relação às\n",
    "demais 10 classes escolhidas da questão anterior? Implemente esta técnica e\n",
    "treine novamente o modelo da questão anterior adaptado usando taxa de\n",
    "aprendizagem=0.001 e número de épocas=50. Compare o resultado com o item\n",
    "anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c1cad9572eaabb49ab774cca14f01d1af5aa597"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir, makedirs\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras import optimizers, regularizers\n",
    "from keras import losses\n",
    "from keras.preprocessing import image\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e03d99ca7e71b016e08721b68da2206a333c6920"
   },
   "outputs": [],
   "source": [
    "RESOLUTION = 150\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "#if you need data augmentation processing\n",
    "#train_datagen = ImageDataGenerator(\n",
    "        #rescale=1./255,\n",
    "        #shear_range=0.2,\n",
    "        #zoom_range=0.2,\n",
    "        #horizontal_flip=True,\n",
    "        #validation_split=0.3)\n",
    "\n",
    "data_datagen_e = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2,\n",
    "                                    horizontal_flip=True, validation_split=0.15)\n",
    "\n",
    "train_generator_e = data_datagen_e.flow_from_directory(\n",
    "        \"../input/simpsons_dataset/simpsons_dataset\",\n",
    "        classes=['homer_simpson', 'ned_flanders', 'moe_szyslak', 'lisa_simpson', \n",
    "                 'bart_simpson', 'marge_simpson', 'krusty_the_clown', \n",
    "                 'principal_skinner', 'charles_montgomery_burns', 'milhouse_van_houten', 'maggie_simpson'],\n",
    "        target_size=(RESOLUTION, RESOLUTION),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical', subset=\"training\")\n",
    "\n",
    "val_generator_e = data_datagen_e.flow_from_directory(\n",
    "        \"../input/simpsons_dataset/simpsons_dataset\",\n",
    "        classes=['homer_simpson', 'ned_flanders', 'moe_szyslak', 'lisa_simpson', \n",
    "                 'bart_simpson', 'marge_simpson', 'krusty_the_clown', \n",
    "                 'principal_skinner', 'charles_montgomery_burns', 'milhouse_van_houten', 'maggie_simpson'],\n",
    "        target_size=(RESOLUTION, RESOLUTION),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical', subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03053493224133b01773ef5fa6ea3545212fa4a6"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters= 100, kernel_size=(5, 5), activation='relu', input_shape=(150, 150, 3))) #(image_height, image_width, image_channels) (not including the batch dimension).\n",
    "model.add(layers.Conv2D(filters= 100, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((4, 4)))\n",
    "model.add(layers.Flatten()) # Output_shape=(None, 3*3*64)\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(11, activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d9d846ded956d02cc4b511a11431313560cbb01",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.adagrad(lr=0.001), metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator_e,\n",
    "        steps_per_epoch=(11854 // BATCH_SIZE),\n",
    "        epochs=50,\n",
    "        validation_data=val_generator_e,\n",
    "        validation_steps=(2085 // BATCH_SIZE) \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae939a6c6be0f7509a24661622392ad122662d7c"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14cd46d17d4c6d20b0d4315a0ca6074d8638520e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
