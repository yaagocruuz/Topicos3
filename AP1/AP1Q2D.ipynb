{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir, makedirs\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras import optimizers, regularizers\n",
    "from keras import losses\n",
    "from keras.preprocessing import image\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a1e135f0929d54d5393f8a9f547e6fc645b9b62"
   },
   "outputs": [],
   "source": [
    "RESOLUTION = 150\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "#if you need data augmentation processing\n",
    "#train_datagen = ImageDataGenerator(\n",
    "        #rescale=1./255,\n",
    "        #shear_range=0.2,\n",
    "        #zoom_range=0.2,\n",
    "        #horizontal_flip=True,\n",
    "        #validation_split=0.3)\n",
    "\n",
    "data_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.15)\n",
    "\n",
    "train_generator = data_datagen.flow_from_directory(\n",
    "        \"../input/simpsons_dataset/simpsons_dataset\",\n",
    "        classes=['homer_simpson', 'ned_flanders', 'moe_szyslak', 'lisa_simpson', \n",
    "                 'bart_simpson', 'marge_simpson', 'krusty_the_clown', \n",
    "                 'principal_skinner', 'charles_montgomery_burns', 'milhouse_van_houten'],\n",
    "        target_size=(RESOLUTION, RESOLUTION),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical', subset=\"training\")\n",
    "\n",
    "val_generator = data_datagen.flow_from_directory(\n",
    "        \"../input/simpsons_dataset/simpsons_dataset\",\n",
    "        classes=['homer_simpson', 'ned_flanders', 'moe_szyslak', 'lisa_simpson', \n",
    "                 'bart_simpson', 'marge_simpson', 'krusty_the_clown', \n",
    "                 'principal_skinner', 'charles_montgomery_burns', 'milhouse_van_houten'],\n",
    "        target_size=(RESOLUTION, RESOLUTION),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical', subset=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "38084760fa2f0706223b03f17e7ef29afd0c3db4"
   },
   "source": [
    "# drop = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "113dec52432cc093f2771100f73a3d955274cf20"
   },
   "outputs": [],
   "source": [
    "model10 = models.Sequential()\n",
    "model10.add(layers.Conv2D(filters= 100, kernel_size=(5, 5), activation='relu', input_shape=(150, 150, 3))) #(image_height, image_width, image_channels) (not including the batch dimension).\n",
    "model10.add(layers.Conv2D(filters= 100, kernel_size=(5, 5), activation='relu'))\n",
    "model10.add(layers.MaxPooling2D((4, 4)))\n",
    "model10.add(layers.Flatten()) # Output_shape=(None, 3*3*64)\n",
    "model10.add(layers.Dropout(0.1))\n",
    "model10.add(layers.Dense(64, activation='relu'))\n",
    "model10.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "model10.compile(loss='categorical_crossentropy', optimizer=optimizers.adagrad(lr=0.001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "baf42553c77440435f6de24cb92589c18f165331"
   },
   "outputs": [],
   "source": [
    "history10 = model10.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=(11745 // BATCH_SIZE),\n",
    "        epochs=50,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=(2066 // BATCH_SIZE) \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0b7e62223e0a9631d6ee726d97f68058a366486"
   },
   "outputs": [],
   "source": [
    "acc = history10.history['acc']\n",
    "val_acc = history10.history['val_acc']\n",
    "loss = history10.history['loss']\n",
    "val_loss = history10.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c9695721cfbf78d0c54b2e4e031b3c6c6c4caac"
   },
   "source": [
    "# drop = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06da9d0dd0f8d67d190c79d74544ad6ecb4a618a"
   },
   "outputs": [],
   "source": [
    "model11 = models.Sequential()\n",
    "model11.add(layers.Conv2D(filters= 100, kernel_size=(5, 5), activation='relu', input_shape=(150, 150, 3))) #(image_height, image_width, image_channels) (not including the batch dimension).\n",
    "model11.add(layers.Conv2D(filters= 100, kernel_size=(5, 5), activation='relu'))\n",
    "model11.add(layers.MaxPooling2D((4, 4)))\n",
    "model11.add(layers.Flatten()) # Output_shape=(None, 3*3*64)\n",
    "model11.add(layers.Dropout(0.3))\n",
    "model11.add(layers.Dense(64, activation='relu'))\n",
    "model11.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "model11.compile(loss='categorical_crossentropy', optimizer=optimizers.adagrad(lr=0.001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d936ebd7e8d842cdc605ecaee467b873e6f3d2d8"
   },
   "outputs": [],
   "source": [
    "acc = history11.history['acc']\n",
    "val_acc = history11.history['val_acc']\n",
    "loss = history11.history['loss']\n",
    "val_loss = history11.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a64037afaf169c470a2dfd1889cc357fcd5dec73"
   },
   "source": [
    "# DROP =0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51916c604413781d4b41451873b6682aa9765f0c"
   },
   "outputs": [],
   "source": [
    "model12 = models.Sequential()\n",
    "model12.add(layers.Conv2D(filters= 100, kernel_size=(5, 5), activation='relu', input_shape=(150, 150, 3))) #(image_height, image_width, image_channels) (not including the batch dimension).\n",
    "model12.add(layers.Conv2D(filters= 100, kernel_size=(5, 5), activation='relu'))\n",
    "model12.add(layers.MaxPooling2D((4, 4)))\n",
    "model12.add(layers.Flatten()) # Output_shape=(None, 3*3*64)\n",
    "model12.add(layers.Dropout(0.5))\n",
    "model12.add(layers.Dense(64, activation='relu'))\n",
    "model12.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "model12.compile(loss='categorical_crossentropy', optimizer=optimizers.adagrad(lr=0.001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85385335663108db4b9c4715b8570aa7273db656"
   },
   "outputs": [],
   "source": [
    "acc = history12.history['acc']\n",
    "val_acc = history12.history['val_acc']\n",
    "loss = history12.history['loss']\n",
    "val_loss = history12.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
